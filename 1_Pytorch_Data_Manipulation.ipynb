{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demirbey05/jarvis.dl/blob/main/1_Pytorch_Data_Manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oLudAaxZnhza"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/huseyin/Codes/jarvis.dl/.venv/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
          ]
        }
      ],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RRxmud8nmNQ",
        "outputId": "447feb21-ce44-4242-8893-1c2f3e7e11f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12])\n",
            "torch.Size([12, 1])\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12,dtype=torch.float16)\n",
        "print(x.shape)\n",
        "print(x.reshape(12,1).shape)\n",
        "print(x.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10JrZDfzoZF5"
      },
      "source": [
        "##¬†Indexing and Slicing\n",
        "\n",
        "Indexed or sliced value shares same data with original tensor, so if you modify it will reflect to original one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAIe5_mjn3iW",
        "outputId": "f7d6cadb-8247-415f-d5ea-5d3f4597f257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]], dtype=torch.float16)\n",
            "tensor([1., 5., 9.], dtype=torch.float16)\n",
            "tensor([ 8.,  9., 10., 11.], dtype=torch.float16)\n",
            "tensor([4., 5., 6., 7.], dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "X = x.reshape(3,4)\n",
        "print(X)\n",
        "print(X[:,1]) #second column\n",
        "print(X[-1,:]) #last row\n",
        "print(X[1]) #¬†second row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt0JWayVotaS",
        "outputId": "67cb1a7d-8565-4ef6-aca4-b8928acbc630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 2.,  6., 10.], dtype=torch.float16)\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "T = X[:,2]\n",
        "print(T)\n",
        "print(T.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R71qbn2ppKZc",
        "outputId": "ed5dbb71-c4a1-4dda-a2a7-9afdada2af79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0.,    1., 1000.,    3.],\n",
            "        [   4.,    5.,    6.,    7.],\n",
            "        [   8.,    9.,   10.,   11.]], dtype=torch.float16)\n",
            "tensor(1000., dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "T[0] = 1000.0\n",
        "print(X)\n",
        "#¬†You will see X[0,2] will be 1000\n",
        "print(X[0,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Z3hma5pxFh"
      },
      "source": [
        "**WARN:** `X[start:stop]`, where\n",
        "**the returned value includes the first index (start) but not the last (stop).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADpq5KJLtsD3"
      },
      "source": [
        "#Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYIE4aYgp9l9",
        "outputId": "aac879f0-7826-43bf-ad7c-aea015713a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]),\n",
              " tensor([[0, 1]]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(3).reshape((3, 1))\n",
        "b = torch.arange(2).reshape((1, 2))\n",
        "\n",
        "a,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgjmh0--tu0N",
        "outputId": "c56f381b-1fe7-4598-cba6-76c53f0c88db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a + b  #¬†must be (3,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjblulaivoyx"
      },
      "source": [
        "Two tensors are ‚Äúbroadcastable‚Äù if the following rules hold:\n",
        "\n",
        "- Each tensor has at least one dimension.\n",
        "- When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must **either be equal, one of them is 1, or one of them does not exist.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3I83m9jv0Qe"
      },
      "source": [
        "Best way to save memory is to use in-place operations, let's show with `id()` function which shows memory address of the object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ0nGv5ht1ei",
        "outputId": "43f4e52a-f512-4f4e-f82d-c556f691ca5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]], dtype=torch.bfloat16) tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.bfloat16)\n",
            "Memory address of X: 5175534576\n",
            "Memory address of Y: 4390623504\n"
          ]
        }
      ],
      "source": [
        "X = torch.arange(12,dtype=torch.bfloat16).reshape(3,4)\n",
        "Y = torch.ones_like(X)\n",
        "print(X,Y)\n",
        "print(f'Memory address of X: {id(X)}')\n",
        "print(f'Memory address of Y: {id(Y)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjk1om1VwGKG",
        "outputId": "44de9d91-a479-49b7-9623-795c9cbfb9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5175535824\n"
          ]
        }
      ],
      "source": [
        "Z = X + Y\n",
        "print(id(Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fju8DDtTwZiX"
      },
      "outputs": [],
      "source": [
        "# We can directly change the data in X\n",
        "X[:] = X + Y\n",
        "#¬†Or X += Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XbO6OHrxhbY"
      },
      "source": [
        "# Linear Algebra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzD1IYF4xBQM",
        "outputId": "aa1bc000-fa25-4e34-da56-f5a322e5be95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show that transpose of transpose equal to original matrix\n",
        "A= torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
        "B = A.T\n",
        "torch.equal(A,B.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_thmbQQRxwv0",
        "outputId": "6389da9f-7dad-405a-d06c-3b6e42fcb43c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We defined the tensor X of shape (2, 3, 4) in this section. What is the output of len(X)?\n",
        "X = torch.ones((2,3,4))\n",
        "len(X) #¬†2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCFjwgAbyG7E",
        "outputId": "98ff4806-3894-4c62-d3f4-8bf92c03b5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5175535152\n",
            "4399125456\n"
          ]
        }
      ],
      "source": [
        "K = torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
        "\n",
        "print(id(torch.transpose(K,1,0)))\n",
        "print(id(K))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqRPN7ZpYZyT"
      },
      "source": [
        "# How Pytorch Stores Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bjt8J4ueIPM"
      },
      "source": [
        "Tensor contains 5 fundamental attributes : `size`,`stride`,`device`,`type`,`layout`. **Pytorch stores tensor with strided way in a memory.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acNFG-_kYcPC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5_2xH7Uj-Qb"
      },
      "source": [
        "# Autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYxbfh8bj_l2",
        "outputId": "c19ab227-26ee-488b-c45d-39d40af737f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "#¬†Let's take derivative of x.T @ x respect to x (Scalar Valued Function !!!!)\n",
        "\n",
        "x = torch.arange(3,dtype=torch.bfloat16,requires_grad =True) #¬†requires_grad must be present\n",
        "print(x.grad) #¬†None by default because we didnt do any process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdb8T1RLk5qw",
        "outputId": "e110c629-8162-4a27-ff45-64b3533b666d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hq/pd61m21j1rs7bpfxqkjssb3c0000gn/T/ipykernel_22066/3718475891.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:4416.)\n",
            "  y = x.T @ x\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(5., dtype=torch.bfloat16, grad_fn=<DotBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = x.T @ x\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMdQmtvelTj9"
      },
      "source": [
        "Pay Attention : `grad_fn=<DotBackward0>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQoGjCFClNVz",
        "outputId": "d1a833b0-ab62-4438-9e64-41e600e65880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 2., 4.], dtype=torch.bfloat16)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#¬†To fill x's grad vector\n",
        "y.backward()\n",
        "print(x.grad)\n",
        "print(torch.equal(x.grad,2 * x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOD_VZk1lkag",
        "outputId": "18cbf3ab-a734-4133-de4e-081dd5f13c69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For another operation we need to reset gradient, because torch is not supporting\n",
        "x.grad.zero_()\n",
        "x.sum().backward()\n",
        "torch.equal(x.grad,torch.ones_like(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WrJx56GNpZYW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 2., 4.], dtype=torch.bfloat16)\n"
          ]
        }
      ],
      "source": [
        "##¬†Now for Non-Scalar Valued Functions\n",
        "## For non-scalar we have to transform non-scalar to scalar\n",
        "\n",
        "x.grad.zero_()\n",
        "y = x * x\n",
        "y.sum().backward()\n",
        "print(x.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SPS2S94qIuz0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.,  3., 12.], dtype=torch.bfloat16)\n"
          ]
        }
      ],
      "source": [
        "#¬†Sometimes we dont want to backpropagation continue from some variable\n",
        "x.grad.zero_()\n",
        "y = x * x \n",
        "z = y * x \n",
        "\n",
        "z.sum().backward()\n",
        "print(x.grad) #¬†3 * x * x = dz/dx = dy/dx * x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Detach y from computation\n",
        "\n",
        "x.grad.zero_()\n",
        "y = x * x \n",
        "u = y.detach()\n",
        "\n",
        "z = u * x\n",
        "z.sum().backward() #¬†I think it makes du/dx = 0 so will be u\n",
        "torch.equal(x.grad,u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let ùëì(ùë•)= sin(ùë•). Plot the graph of ùëì and of its derivative ùëì‚Ä≤. Do not exploit the fact\n",
        "that ùëì‚Ä≤(ùë•)= cos(ùë•)but rather use automatic differentiation to get the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.arange(0,12,0.1,dtype=torch.float32,requires_grad=True)\n",
        "y = torch.sin(x)\n",
        "y.sum().backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "delx = x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNIDcVmM+tZxsgN13n3a92P",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
